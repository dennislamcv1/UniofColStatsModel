{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "761063bac57eb0ce2c8947a6ae38aa67",
     "grade": false,
     "grade_id": "cell-b0678bc2ade938c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Module 3 - Autograded Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c6bcda2d4ce939b88ed04a1817c2c12",
     "grade": false,
     "grade_id": "cell-1a745cbf4489d831",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Outline:\n",
    "**Here are the objectives of this assignment:**\n",
    "\n",
    "1. Utilize F-tests to distinguish between statistically different models.\n",
    "2. Calculate Confidence Intervals for feature parameters to understand their variability.\n",
    "3. Reinforce an understanding of Confidence Intervals by comparing many different CIs from the same underlying population.\n",
    "4. Improve general familiarity with R, including utilizing data frames and ggplot.\n",
    "\n",
    "**Here are some general tips:**\n",
    "\n",
    "1. Read the questions carefully to understand what is being asked.\n",
    "2. When you feel that your work is completed, feel free to hit the ```Validate``` button to see your results on the *visible* unit tests. If you have questions about unit testing, please refer to the \"Module 0: Introduction\" notebook provided as an optional resource for this course. In this assignment, there are hidden unit tests that check your code. You will not recieve any feedback for failed hidden unit tests until the assignment is submitted. **Do not misinterpret the feedback from visible unit tests as all possible tests for a given question--write your code carefully!**\n",
    "3. Before submitting, we recommend restarting the kernel and running all the cells in order that they appear to make sure that there are no additional bugs in your code.\n",
    "4. There are 50 points total in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61976035999845ba5dc73e368bdaaee2",
     "grade": false,
     "grade_id": "cell-ac1dc753013a8391",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell loads the necesary libraries for this assignment\n",
    "library(testthat)\n",
    "library(tidyverse)\n",
    "library(RCurl)  # a package that includes the function getURL(), which allows for reading data from github.\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2720e1dcfd363273e0e0c613d3d2ac16",
     "grade": false,
     "grade_id": "cell-fa86438d7bacf1bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 1: Comparing Models \n",
    "\n",
    "In this exercise, we will fit multiple different models to the same data and determine which of those models we should ultimately use.\n",
    "\n",
    "The data we will be using is the Auto MPG Data Set from the UCI Machine Learning Repository. It contains technical specifications and performance ratings of many different cars. We will focus on the features that impact the overall `mpg` of each car.\n",
    "\n",
    "In the cell below, code is provided for you to load in the data and rename the columns to be more specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "552d10f50b2bbec075a2da4cb1c333df",
     "grade": false,
     "grade_id": "cell-05593d2f7383983e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mpg.data = read_table(\"auto-mpg.data\")\n",
    "names(mpg.data) = c(\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \n",
    "                    \"accel\", \"model_year\", \"origin\", \"car_name\")\n",
    "mpg.data$horsepower = as.numeric(mpg.data$horsepower)\n",
    "mpg.data = na.omit(mpg.data)\n",
    "\n",
    "summary(mpg.data)\n",
    "str(mpg.data)\n",
    "head(mpg.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73e43f9fceffd6824505dd99f1c95377",
     "grade": false,
     "grade_id": "cell-7657834bf882281a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1. (a) Three Different Models (5 points)\n",
    "\n",
    "We will fit three different models to this data:\n",
    "\n",
    "1. `mod.1`: Fits `mpg` as the response with `weight` as the predictor.\n",
    "2. `mod.2`: Fits `mpg` as the response with `weight` and `accel` as predictors.\n",
    "3. `mod.3`: Fits `mpg` as the response with `weight`, `accel` and `horsepower` as predictors.\n",
    "\n",
    "Fit these models in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc05c6755177db24e1d2a9a98fddf6e6",
     "grade": false,
     "grade_id": "cell-0364ff2727567909",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mod.1 = NA\n",
    "mod.2 = NA\n",
    "mod.3 = NA\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed3bef036bc9792aadaabd233aa8acdc",
     "grade": true,
     "grade_id": "cell-0b3a8eb5eb687c4e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# Make sure that each model is a linear model\n",
    "if(test_that(\"Testing model types\", \n",
    "             {(expect_is(mod.1, \"lm\"))\n",
    "              (expect_is(mod.2, \"lm\"))\n",
    "              (expect_is(mod.3, \"lm\"))})){\n",
    "    print(\"All models are linear models.\")\n",
    "}else{\n",
    "    print(\"At least one of the models isn't a linear model!\")\n",
    "    print(\"Make sure you're using the lm() function.\")\n",
    "}\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f8533bf3b3f149f407531bde655b99e",
     "grade": false,
     "grade_id": "cell-9eab12430a54ff8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1. (b) Partial F-Tests (10 points)\n",
    "\n",
    "Compare the 3 models using pairwise F-tests to determine which of the three we should use moving forward. It may be helpful to write out the null and alternative hypotheses for these tests.\n",
    "\n",
    "Copy your selected model into the `final.model` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c23eee6ea4829fc6ba3c6bf5865ba646",
     "grade": false,
     "grade_id": "cell-f4463bbaa5fc26ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "final.model = NA\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23f583769d9cdbca56021754d86eeda5",
     "grade": true,
     "grade_id": "cell-3c38c722058b4576",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "if(test_that(\"Check final.model class\", {expect_is(final.model, \"lm\")})){\n",
    "    print(\"You've selected a model! Make sure you're confident in your answer.\")\n",
    "}else{\n",
    "    print(\"final.model is not a linear model.\")\n",
    "    print(\"To copy the selected model use `final.model = mod.#`\")\n",
    "}\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b4f3eb03177179138cd739d188cedcd",
     "grade": false,
     "grade_id": "cell-d9c61c50ae399a94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1. (c) Coefficient Confidence Intervals (10 points)\n",
    "\n",
    "Using your selected best model, calculate a $95\\%$ confidence interval for the `weight` parameter. Save the lower and upper values into `weight.CI.lower` and `weight.CI.upper` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3139e3f1dddcf962ff5d8a8847edf28",
     "grade": false,
     "grade_id": "cell-0288544f5b234bab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "weight.CI.lower = NA\n",
    "weight.CI.upper = NA\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c2c58fadd1515cadfb007237ab7c613",
     "grade": true,
     "grade_id": "cell-196c4b28f7f44d76",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11bb206e072850d6a0ef5e454dd1907f",
     "grade": false,
     "grade_id": "cell-3dcc0ddc69353e65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1. (d) Model Comparison (5 points)\n",
    "\n",
    "So far, we've used the F-test as a way to choose a \"best\" model among the three proposed. Now let's compare the models according to their mean squared errors (MSE). Compute the MSE for each of the three models and save their values into their respective `MSE.#` variables.\n",
    "\n",
    "Which of these models has the best MSE? Do these conclusions agree with the model you selected in part **1.b**? Think about why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74ac93bb9c31be08a00fe586d07f6bab",
     "grade": false,
     "grade_id": "cell-436d726601f9377a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "MSE.1 = NA\n",
    "MSE.2 = NA\n",
    "MSE.3 = NA\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "036045bad5539141a14a8d762f5be3b4",
     "grade": true,
     "grade_id": "cell-7700c89c1209fc31",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7ba57714c003f42ddddb38dff976792",
     "grade": false,
     "grade_id": "cell-69ef17c11b5e5185",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 2: Large Datasets and Significance\n",
    "\n",
    "For this exercise, we will see if we can create a \"good\" regression model for a city's temperature using other weather data. The data is from hourly weather records of Szeged, Hungary from 2006-2016. The data was provided by [Darksky.net](https://darksky.net/forecast/46.2543,20.1484/us12/en) and can be found on Kaggle [here](https://www.kaggle.com/budincsevity/szeged-weather). The data has not been modified in any way.\n",
    "\n",
    "The data is loaded in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f7c55a56cecc71dfce04690c73de58e",
     "grade": false,
     "grade_id": "cell-1971d7b6e0ebeae4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "weather.data = read.csv(\"weatherHistory.csv\")\n",
    "weather.data = na.omit(weather.data)\n",
    "head(weather.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44094157d372bed3eab0aafb1187b617",
     "grade": false,
     "grade_id": "cell-f344fd713712ab8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2. (a) Talking about the weather. (5 points)\n",
    "\n",
    "Before we jump into modeling, let's think about weather. Is temperature correlated with wind speed, visibility or pressure? Certainly somewhat, but probably not to a great extent. Let's find out exactly (at least for these data).\n",
    "\n",
    "Determine the correlation between `Temperature..C.` and the three predictors: `Wind.Speed..km.h.`, `Visibility..km.` and `Pressure..millibars.`. Store these values in `cor.speed`, `cor.vis` and `cor.pres` respectively.\n",
    "\n",
    "Also, if our data is hourly records over 10 years, then we're going to have a lot of records. How many rows does our dataset have? Store this value in `data.n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3718830ddf25aceaa4f4622b16b9d7d1",
     "grade": false,
     "grade_id": "cell-183aa8dd084821d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cor.speed = NA\n",
    "cor.vis = NA\n",
    "cor.pres = NA\n",
    "data.n = NA\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3516f1f8e57aa15d13db0239fe335dc",
     "grade": true,
     "grade_id": "cell-d49e30e6fc06af1b",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cf4625f3275039584374595ab750aaf",
     "grade": false,
     "grade_id": "cell-7ffa8fb830c5cecf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2. (b) Data Size Matters (5 points)\n",
    "\n",
    "Yep, that's a lot of data. But isn't more data better? Well, let's find out. We can create two different models, one with a little data and one with a lot of data, and determine if the one fit to more data is the better model.\n",
    "\n",
    "Fit two models to the data, with `Temperature..C.` as the response and `Wind.Speed..km.h.`, `Visibility..km.` and `Pressure..millibars.` as predictors. The first model, `weather.lmod.small`, should be fit to the first $30$ rows of the data. The second model, `weather.lmod.all`, should be fit to all the data.\n",
    "\n",
    "Look at the p-values of the model coefficients. What can you infer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3dab6bd5e987f9470d88ad7aa7370008",
     "grade": false,
     "grade_id": "cell-eb2ca4250cac617d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "weather.lmod.small = NA\n",
    "weather.lmod.all = NA\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e23cd9f3f994f0f7d8beafefa4fdc7dd",
     "grade": true,
     "grade_id": "cell-9eab1b9dd437a011",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "363eb85c262d81dfa6aa67bcd8f23148",
     "grade": false,
     "grade_id": "cell-8ae5c673231343f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2. (c) Interpreting Our Models (10 points)\n",
    "\n",
    "Answer the following questions and put your answer with the corresponding answer number.\n",
    "\n",
    "1. TRUE/FALSE. The coefficient for `Pressure..millibars.` for the model fit to all the data is statistically signficant.\n",
    "2. TRUE/FALSE. The coefficient for `Pressure..millibars.` for the model fit to a small amount of data is statistically significant.\n",
    "3. What is the $R^2$ for the model fit to all of the data?\n",
    "4. What is the $R^2$ for the model fit to a small amount of the data?\n",
    "5. Which model explained more variablility in its respective dataset? Copy the correct model into this answer variable. Think about why this is the case!\n",
    "5. TRUE/FALSE. Models fit to large amounts of data run the risk of having statistically significant coefficients, even if the predictor isn't practically significant to the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c93729d76bc9ec7e2aabb805fcdf8ead",
     "grade": false,
     "grade_id": "cell-c329089f0eb2b6f3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "prob.3.c.1 = NA\n",
    "\n",
    "prob.3.c.2 = NA\n",
    "\n",
    "prob.3.c.3 = NA\n",
    "\n",
    "prob.3.c.4 = NA\n",
    "\n",
    "# Save the selected model into this variable.\n",
    "prob.3.c.5 = NA\n",
    "\n",
    "prob.3.c.6 = NA\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dea55f2761fb3ae58ddb2bf2bff3343",
     "grade": true,
     "grade_id": "cell-b8d62d399926fdd3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL\n",
    "if (!test_that(\"Checking type() of answer\", expect_is(prob.3.c.5, \"lm\"))){\n",
    "    print(\"Make sure prob.3.c.5 is your selected linear model. Should be of type 'lm'\")\n",
    "}\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a026db6ef3d760f33f13a9766e6b0ef2",
     "grade": true,
     "grade_id": "cell-747d04a23ecfa06c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "185314335da265b3ab458149e32c2a7b",
     "grade": true,
     "grade_id": "cell-13617391a174785a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9ba773825acd4ee183595b0b4e3f0b5",
     "grade": true,
     "grade_id": "cell-ca4245dd068ab3b8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d1a6a7ee1677d02467351adf77cd2ab",
     "grade": true,
     "grade_id": "cell-696e053bc707a622",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87f29b8f40f26e4977f61e3d9b4cb0bc",
     "grade": true,
     "grade_id": "cell-7df0a366e15ea33c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
