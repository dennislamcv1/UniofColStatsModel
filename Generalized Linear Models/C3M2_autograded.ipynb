{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13c99c961bb123aa28c49dc36dc169d8",
     "grade": false,
     "grade_id": "cell-efccf958eed0aeba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# C3M2: Autograded Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17b08b40e677182b10e3fb78c8fc1e9f",
     "grade": false,
     "grade_id": "cell-7ab2b43d34632de1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Outline:\n",
    "**Here are the objectives of this assignment:**\n",
    "\n",
    "1. Understand when to apply different kinds of regression models.\n",
    "2. Fit a GLM to count data and go through model diagnostics and interpretation.\n",
    "3. Compare the effectiveness of GLMs to Linear Regression models.\n",
    "\n",
    "**Here are some general tips:**\n",
    "\n",
    "1. Read the questions carefully to understand what is being asked.\n",
    "2. When you feel that your work is completed, feel free to hit the ```Validate``` button to see your results on the *visible* unit tests. If you have questions about unit testing, please refer to the \"Module 0: Introduction\" notebook provided as an optional resource for this course. In this assignment, there are hidden unit tests that check your code. You will not recieve any feedback for failed hidden unit tests until the assignment is submitted. **Do not misinterpret the feedback from visible unit tests as all possible tests for a given question--write your code carefully!**\n",
    "3. Before submitting, we recommend restarting the kernel and running all the cells in order that they appear to make sure that there are no additional bugs in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31092c4e79d1fa81d68bce1ea6fc0da6",
     "grade": false,
     "grade_id": "cell-1dfd99e4fcf51b8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load required packages\n",
    "library(tidyverse)\n",
    "library(testthat)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ce6c2ce27267a4c7eddecc545cd480d",
     "grade": false,
     "grade_id": "cell-557d703ad242eb47",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 1: Counts, Rates and Measurements. (15 points)\n",
    "\n",
    "As we've seen, there are many kinds of models for the many kinds of data out there, and fitting a good model start with understanding the data. For the following questions, determine which kind of model should be used for the specified data and question.\n",
    "\n",
    "For each question, input the string answer of the specified model in the respective answer variable. Choose your answers from the models: `\"linear\"`, `\"binomial\"` and `\"poisson\"`, case sensitive. Note: Some features may be suitable for different kinds of models. Pick the model that would work the best.\n",
    "\n",
    "1. You are trying to predict the number of home run scored by baseball players during their next season. Your predictors are the player's age, the number of years spent in professional baseball, and the number of home runs they scored in the previous $5$ years.\n",
    "2. You are trying to determine whether people in cities buy more cereal than people in suburbs or in rural areas. Your response is the number of cereal boxes sold, rounded to the nearest $1000$. Your predictors are the type of area, the population, the number of grocery stores, and the average cost.\n",
    "3. You want to predict ratings for hotels based on user reviews. The rating is on a scale of $1$ to $5$ stars. The predictors are different statistics extracted from their review, such as word count and the number of times the review used the word \"bathroom.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65ef8fa7550054de17d2925be9db7187",
     "grade": false,
     "grade_id": "cell-340a5c66f859c6d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember, your answers should be strings\n",
    "prob.1.1 = NA\n",
    "\n",
    "prob.1.2 = NA\n",
    "\n",
    "prob.1.3 = NA\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1004c4c7cc78431d27e3fa396088a73b",
     "grade": true,
     "grade_id": "cell-724da27dc1880c87",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "if(!test_that(\"Checking answer types\", {expect_is(prob.1.1, \"character\")\n",
    "                                        expect_is(prob.1.2, \"character\")\n",
    "                                        expect_is(prob.1.3, \"character\")})){\n",
    "    print(\"Make sure your answers are strings!\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d79dca1ea29c35aec70d693293d39836",
     "grade": true,
     "grade_id": "cell-4e9ce2437e82ab4c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81475a7ccbd7c2e26192ee819d029467",
     "grade": true,
     "grade_id": "cell-9cab605d4dfedd70",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3817bce336fc09b18133bb4691cccb88",
     "grade": false,
     "grade_id": "cell-993e5a1779d944e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 2: MLRs vs. GLMs\n",
    "\n",
    "For each 30 Galapagos islands, we have a count of the number of plant species found on each island and the number that are endemic to that island. We also have five geographic variables for each island. \n",
    "\n",
    "1. Species: the number of plant species found on the island\n",
    "2. Endemics: the number of endemic species\n",
    "3. Area: the area of the island (km$^2$)\n",
    "4. Elevation: the highest elevation of the island (m)\n",
    "5. Nearest: the distance from the nearest island (km)\n",
    "6. Scruz: the distance from Santa Cruz island (km)\n",
    "7. Adjacent: the area of the adjacent island (square km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12019b2d7d007c8ad026068179736101",
     "grade": false,
     "grade_id": "cell-a619e56a7a080f87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data.gala = read.csv(\"gala.csv\")\n",
    "\n",
    "colnames(data.gala)[1] = \"Location\"\n",
    "data.gala$Location = as.character(data.gala$Location)\n",
    "head(data.gala)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b325da45337337ec49ea9ebd1b02fbc",
     "grade": false,
     "grade_id": "cell-af181788df0a59a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. (a) Trying a Linear Model (15 points)\n",
    "\n",
    "Fit a linear model called `lmod.gala` with `Species` as the response and all other variables, except `Location` and `Endemics`, as predictors. Run some diagnostics and think about why this model may not be the best fit. For each assumption variable, answer `TRUE` if the assumptoin is being met by the model, and `FALSE` if the assumption is not being met by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f99a6ad010205c91fccfa82d89400bb9",
     "grade": false,
     "grade_id": "cell-265adce9bc5f9356",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lmod.gala = NA\n",
    "# Code the following as TRUE or FALSE\n",
    "lmod.gala.linear = NA\n",
    "lmod.gala.homoskedasticity = NA\n",
    "lmod.gala.normality = NA\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "340d9290ea35fa0f04f98154425522f4",
     "grade": true,
     "grade_id": "cell-fcdd78da7e2bf672",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "if(!test_that(\"Checking if model coefficients are correct\", {expect_equal(7.068221, as.numeric(lmod.gala$coef[1]), tol=1e-4)\n",
    "                                                             expect_equal(-0.023938, as.numeric(lmod.gala$coef[2]), tol=1e-4)\n",
    "                                                             expect_equal(0.319456, as.numeric(lmod.gala$coef[3]), tol=1e-4)})){\n",
    "    print(\"At least one of the coefficients was wrong. Make sure your model is correct before doing diagnostics.\")\n",
    "}\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d453a8202e6f66cf72524df9cfb4faa",
     "grade": true,
     "grade_id": "cell-e35e134f322dbe5d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a461723b8992c472c79bd72a6d5d8d9b",
     "grade": true,
     "grade_id": "cell-665bc65bb20b94aa",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "177d9e5b7c81c486043d984ecfac4604",
     "grade": false,
     "grade_id": "cell-3b29caf0d4a4c76e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. (b) Linear Transformations (8 points)\n",
    "\n",
    "Recall that one strategy we used to address models that had nonconstant variance was to transform the response variable. Try the square root transform on the response fit to the same predictors. Store this model as `lmod.gala.sqrt`. Look at the diagnostic plots and consider if this model's assumptions are better than the last. Similar to the previous problem, for each assumption, answer `TRUE` if the model meets the assumption `FALSE` if not. Note that if a plot looks ambiguous, you can interpret it as \"no evidence of a violation\" and answer `TRUE`.\n",
    "\n",
    "One thing to keep in mind is that transformations make the model harder to interpret. Think about how a $1$ unit increase in `Nearest` for your transformed model would affect `Species`. Put your answers into `sqrt.gala.linearity`, `sqrt.gala.homoskedasticity` and `sqrt.gala.normality`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed34beb81ddb5cc33ff1a02fd4f010b9",
     "grade": false,
     "grade_id": "cell-b9976ba66035ecde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lmod.gala.sqrt = NA\n",
    "sqrt.gala.linearity = NA\n",
    "sqrt.gala.homoskedasticity = NA\n",
    "sqrt.gala.normality = NA\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1659f0f59d759d21c2253cd62e59f07",
     "grade": true,
     "grade_id": "cell-8b2ba5fb3d78d832",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43bf966d58886bf53f972b8f07e1e6f1",
     "grade": true,
     "grade_id": "cell-51c721861b2c0848",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac1be98f4df64041783b33e2f7fa6edc",
     "grade": false,
     "grade_id": "cell-d9a4ae8035bc8627",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. (c) GLMs to the Rescue (6 points)\n",
    "\n",
    "There's still some problems with the model. Because our response variable is counts, maybe linear models aren't the best anyways. Fit a GLM of appropriate family to the (untransformed) data, using the same predictors. Store this model as `glm.gala`. Plot the diagnostics plots and think about what assumptions should be met.\n",
    "\n",
    "How do we interpret this model? In particular, fill in the blank: \"A 1-unit increase in `Elevation` is associated with a multiplicative increase of $\\text{_____}$ in `Species`, on average.\" Store this value as `glm.interp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7b0d882ee3aca1a34a7530c97ace27a",
     "grade": false,
     "grade_id": "cell-c8563dcfc34fc1ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "glm.gala = NA\n",
    "glm.interp = NA\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4854011a0e2a02b9cfe8aa9845f02d2b",
     "grade": true,
     "grade_id": "cell-ffbb3e3983e8db85",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "756cc1dd89d331c238f6b23a7bd6de2e",
     "grade": true,
     "grade_id": "cell-2f833909d3198c77",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b18d9629b38fa2d653a61c141bd86117",
     "grade": true,
     "grade_id": "cell-c157c2f762676f1e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6c095c31581dca22b113bf30659c7b5",
     "grade": false,
     "grade_id": "cell-4d8cef1d6f67ab92",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. (d) GLM Goodness of Fit (6 points)\n",
    "\n",
    "Our linear models didn't do a great job of fitting the data, how do we know if our GLM fits the data any better? Well, we don't have an easy scale of reference, like the $R^2$ value, for GLMs. What we can do is compare our model to other models, such as the null model, and see if ours performs significantly better.\n",
    "\n",
    "Calculate the deviance of your model and store it as `glm.deviance`. Then check the goodness of fit of your model using Pearson's $\\chi^2$ statistic. Store this value as `glm.chisq.stat`. Calculate the p-value for this statistic and store it as `glm.chisq.pval`. What does this tell you about your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49d0382a93d5b27848a5ac1d40db837a",
     "grade": false,
     "grade_id": "cell-f4d7f67cb4e7d801",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "glm.deviance = NA\n",
    "glm.chisq.stat = NA\n",
    "glm.chisq.stat = NA\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7410e4d1a94a69e98f68ef3996270fb6",
     "grade": true,
     "grade_id": "cell-16aa8364161967a2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c6d8aeb81220fdd43ae16ef4581ea40",
     "grade": true,
     "grade_id": "cell-f8f057d9d4abe494",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e53b4e19d6020e37fb09076482a7349",
     "grade": true,
     "grade_id": "cell-4b58cc48831ff52a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
