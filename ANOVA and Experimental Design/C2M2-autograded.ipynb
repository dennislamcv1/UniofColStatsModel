{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "470f6366741e3e99f8a4afd490dcd464",
     "grade": false,
     "grade_id": "cell-a94c82130592e169",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# C2M2: Autograded Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "330005b444a8834ce73c96608dca399f",
     "grade": false,
     "grade_id": "cell-b2af68f6941f8de6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Outline:\n",
    "**Here are the objectives of this assignment:**\n",
    "\n",
    "1. \n",
    "\n",
    "**Here are some general tips:**\n",
    "\n",
    "1. Read the questions carefully to understand what is being asked.\n",
    "2. When you feel that your work is completed, feel free to hit the ```Validate``` button to see your results on the *visible* unit tests. If you have questions about unit testing, please refer to the \"Module 0: Introduction\" notebook provided as an optional resource for this course. In this assignment, there are hidden unit tests that check your code. You will not recieve any feedback for failed hidden unit tests until the assignment is submitted. **Do not misinterpret the feedback from visible unit tests as all possible tests for a given question--write your code carefully!**\n",
    "3. Before submitting, we recommend restarting the kernel and running all the cells in order that they appear to make sure that there are no additional bugs in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9132a7355b7cf21d9b6e1c9698f52287",
     "grade": false,
     "grade_id": "cell-546277e075c14cff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.0     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.1     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 0.8.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m  masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mis_null()\u001b[39m masks \u001b[34mtestthat\u001b[39m::is_null()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m     masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mmatches()\u001b[39m masks \u001b[34mtidyr\u001b[39m::matches(), \u001b[34mtestthat\u001b[39m::matches()\n",
      "\n",
      "\n",
      "Attaching package: ‘RCurl’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    complete\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load required libraries\n",
    "library(testthat)\n",
    "library(tidyverse)\n",
    "library(RCurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1817e58872f4b22b3780b1b310cb201c",
     "grade": false,
     "grade_id": "cell-59a16ac3b6ff3559",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 1: Post-Hoc Tests\n",
    "\n",
    "Recently, your local highschool switched their student lunches from circular pizzas to square pizzas. Suprisingly the school reported a change in the overall testing of students in the following weeks. The school decided to test this theory, and has recorded test results following lunches with four different shaped pizzas. It is up to you to determine if the shapes of pizza does in fact improve student's abilities to take tests, and if so, which shaped pizza results in the best test scores.\n",
    "\n",
    "The school has tested four different shapes, coded as the following:\n",
    "* a: Circular\n",
    "* b: Square\n",
    "* c: Triangular\n",
    "* d: Cylindrical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36510e9c35d424e4f3e125f8b9ebd5d9",
     "grade": false,
     "grade_id": "cell-442113d620fd626a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>shape</th><th scope=col>score</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>a</td><td>78.44676</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>a</td><td>88.75349</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>a</td><td>80.19209</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>a</td><td>84.04420</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>a</td><td>78.50873</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>a</td><td>82.34018</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & X & shape & score\\\\\n",
       "  & <int> & <fct> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & a & 78.44676\\\\\n",
       "\t2 & 2 & a & 88.75349\\\\\n",
       "\t3 & 3 & a & 80.19209\\\\\n",
       "\t4 & 4 & a & 84.04420\\\\\n",
       "\t5 & 5 & a & 78.50873\\\\\n",
       "\t6 & 6 & a & 82.34018\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 3\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | shape &lt;fct&gt; | score &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 1 | a | 78.44676 |\n",
       "| 2 | 2 | a | 88.75349 |\n",
       "| 3 | 3 | a | 80.19209 |\n",
       "| 4 | 4 | a | 84.04420 |\n",
       "| 5 | 5 | a | 78.50873 |\n",
       "| 6 | 6 | a | 82.34018 |\n",
       "\n"
      ],
      "text/plain": [
       "  X shape score   \n",
       "1 1 a     78.44676\n",
       "2 2 a     88.75349\n",
       "3 3 a     80.19209\n",
       "4 4 a     84.04420\n",
       "5 5 a     78.50873\n",
       "6 6 a     82.34018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>992</li><li>3</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 992\n",
       "\\item 3\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 992\n",
       "2. 3\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 992   3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "df.pizza = read.csv(\"pizza.csv\")\n",
    "head(df.pizza)\n",
    "dim(df.pizza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcfb0ae089ef16f68fb34c0b543cf093",
     "grade": false,
     "grade_id": "cell-3bc1cc34d339933e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. (a) Intuition and ANOVA\n",
    "\n",
    "Instead of jumping into direct comparisons, we should check all the pizza shapes resulted in the same scores. Or, in other words, if at least one shape resulted in different test scores than the others.\n",
    "\n",
    "Using ggplot, create a boxplot of the different shapes. Save your boxplot as `pizza.boxplot`.\n",
    "\n",
    "Then determine if at least one shape resulted in different test scores than the others. In `pizza.diff`, answer `TRUE` if there is a difference and `FALSE` if there is not a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32e0b537ef8220bfed45e059c90d06db",
     "grade": false,
     "grade_id": "cell-3bc5cd259f0ffa06",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pizza.boxplot = ggplot(df.pizza, aes(x=shape, y=score)) + geom_boxplot()\n",
    "pizza.diff = TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd213e4dbb57c85f6624994873852091",
     "grade": true,
     "grade_id": "cell-1b6b8546f9993b60",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "66ecaa4205049c69d350ce359f205685",
     "grade": false,
     "grade_id": "cell-4999a2b53512bdac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. (b) Type I Error Rate\n",
    "\n",
    "The problem with pairwise tests is that of compounding error. As each test has a probability of getting an incorrect answer, then  the chance of at least one test being incorrect increases as you increase the number of tests. For the following, use a significance of $\\alpha = 0.05$.\n",
    "\n",
    "For our data, calculate the probability that at least one test has type 1 error if we conduct pair-wise comparisons for all combinations of labels? Store your answer in `pizza.error`.\n",
    "\n",
    "Then determine the probability that at least one test has type 1 error for all possible pairwise tests, using the Bonferroni correction. Store your answer as `bonferroni.error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b58fda624826ffd7a37c0bbf99ae37d7",
     "grade": false,
     "grade_id": "cell-a99a317269034580",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "6"
      ],
      "text/latex": [
       "6"
      ],
      "text/markdown": [
       "6"
      ],
      "text/plain": [
       "[1] 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.264908109375"
      ],
      "text/latex": [
       "0.264908109375"
      ],
      "text/markdown": [
       "0.264908109375"
      ],
      "text/plain": [
       "[1] 0.2649081"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0489698353102359"
      ],
      "text/latex": [
       "0.0489698353102359"
      ],
      "text/markdown": [
       "0.0489698353102359"
      ],
      "text/plain": [
       "[1] 0.04896984"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k <- 4\n",
    "n_comparisons <- choose(k, 2)\n",
    "n_comparisons\n",
    "\n",
    "\n",
    "alpha <- 0.05\n",
    "pizza.error <- 1 - (1 - alpha)^n_comparisons\n",
    "pizza.error\n",
    "\n",
    "bonferroni_alpha <- alpha / n_comparisons\n",
    "bonferroni.error <- 1 - (1 - bonferroni_alpha)^n_comparisons\n",
    "bonferroni.error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a06c69719e2d23001e51cd2c9aff4b9",
     "grade": true,
     "grade_id": "cell-922323c7abb74c4c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2aeb681ec971ede57ad9a27e0d828c5",
     "grade": false,
     "grade_id": "cell-0c727c50291d51ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. (c) Tukey's Test\n",
    "\n",
    "Now let's do our post-hoc tests. Using Tukey's Test, determine which shapes result in the same test scores. Store the pairs of shapes that are the same in a dataframe named `pizza.post.hoc` with the first column named `shape.1` and second column named `shape.2`.\n",
    "\n",
    "For example, if `a-b` and `a-c` are the only two shapes that result in the same scores, your final dataframe would be created by:\n",
    "\n",
    "`data.frame(shape.1=c(\"a\", \"a\"), shape.2=c(\"b\", \"c\"))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae133487466b8c045460525042c4276b",
     "grade": false,
     "grade_id": "cell-4ccae0e4e7a7a331",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 2 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>shape.1</th><th scope=col>shape.2</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>d</td><td>a</td></tr>\n",
       "\t<tr><td>d</td><td>c</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 × 2\n",
       "\\begin{tabular}{ll}\n",
       " shape.1 & shape.2\\\\\n",
       " <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t d & a\\\\\n",
       "\t d & c\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 × 2\n",
       "\n",
       "| shape.1 &lt;fct&gt; | shape.2 &lt;fct&gt; |\n",
       "|---|---|\n",
       "| d | a |\n",
       "| d | c |\n",
       "\n"
      ],
      "text/plain": [
       "  shape.1 shape.2\n",
       "1 d       a      \n",
       "2 d       c      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANOVA test\n",
    "anova_model <- aov(score ~ shape, data = df.pizza)\n",
    "\n",
    "anova_result <- summary(anova_model)\n",
    "\n",
    "# Tukey's post-hoc test\n",
    "tukey_result <- TukeyHSD(anova_model)\n",
    "\n",
    "# Extract significant pairs\n",
    "tukey_pairs <- as.data.frame(tukey_result$shape)\n",
    "tukey_pairs <- tukey_pairs %>%\n",
    "  rownames_to_column(var = \"comparison\") %>%\n",
    "  separate(comparison, into = c(\"shape.1\", \"shape.2\"), sep = \"-\")\n",
    "\n",
    "significant_pairs <- tukey_pairs %>% filter(`p adj` >= 0.05)\n",
    "\n",
    "# Ensure the result is a dataframe\n",
    "pizza.post.hoc <- data.frame(shape.1 = significant_pairs$shape.1,\n",
    "                             shape.2 = significant_pairs$shape.2)\n",
    "\n",
    "pizza.post.hoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73aa73941d47a6f01b7e0666f1fc39f0",
     "grade": true,
     "grade_id": "cell-1a6c3e41843eb805",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "\n",
    "test_that(\"Check that answer is a dataframe\", expect_is(pizza.post.hoc, \"data.frame\"))\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f51e17472c56ef28edf837d7877f3ce",
     "grade": false,
     "grade_id": "cell-97958536f9ae09d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. (d) Bonferroni's Correction\n",
    "\n",
    "Repeat the calculations from **1.c**, but include the Bonferroni Correction in your calculations. Report the pairs of shapes in a dataframe named `bonferroni.post.hoc`, of the same specifications as in **1.c**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9a8b06a02c12d6b743365226bfb26d9",
     "grade": false,
     "grade_id": "cell-7c0317180b596644",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 3 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>shape.1</th><th scope=col>shape.2</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>c</td><td>a</td></tr>\n",
       "\t<tr><td>d</td><td>a</td></tr>\n",
       "\t<tr><td>d</td><td>c</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 2\n",
       "\\begin{tabular}{ll}\n",
       " shape.1 & shape.2\\\\\n",
       " <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t c & a\\\\\n",
       "\t d & a\\\\\n",
       "\t d & c\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 2\n",
       "\n",
       "| shape.1 &lt;fct&gt; | shape.2 &lt;fct&gt; |\n",
       "|---|---|\n",
       "| c | a |\n",
       "| d | a |\n",
       "| d | c |\n",
       "\n"
      ],
      "text/plain": [
       "  shape.1 shape.2\n",
       "1 c       a      \n",
       "2 d       a      \n",
       "3 d       c      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tukey's post-hoc test\n",
    "tukey_result <- TukeyHSD(anova_model)\n",
    "\n",
    "# Extract significant pairs\n",
    "tukey_pairs <- as.data.frame(tukey_result$shape)\n",
    "tukey_pairs <- tukey_pairs %>%\n",
    "  rownames_to_column(var = \"comparison\") %>%\n",
    "  separate(comparison, into = c(\"shape.1\", \"shape.2\"), sep = \"-\")\n",
    "\n",
    "# Number of comparisons\n",
    "n_comparisons <- nrow(tukey_pairs)\n",
    "\n",
    "# Apply Bonferroni correction: divide the significance level by the number of comparisons\n",
    "bonferroni_alpha <- 0.05 / n_comparisons\n",
    "\n",
    "# Filter pairs where the p-value is greater than or equal to the Bonferroni-adjusted alpha\n",
    "significant_pairs_bonferroni <- tukey_pairs %>%\n",
    "  filter(`p adj` >= bonferroni_alpha)\n",
    "\n",
    "# Create the final dataframe\n",
    "bonferroni.post.hoc <- data.frame(shape.1 = significant_pairs_bonferroni$shape.1,\n",
    "                                  shape.2 = significant_pairs_bonferroni$shape.2)\n",
    "\n",
    "# Display the result\n",
    "bonferroni.post.hoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5188de7352f62cee77914a566080ab07",
     "grade": true,
     "grade_id": "cell-906af4cd79742e5a",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c25343c82bab05cd5eb66c61a16c3a84",
     "grade": false,
     "grade_id": "cell-4e5a679c01173292",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 2: The Great Gum Debacle (16 Points)\n",
    "\n",
    "Consider the following experiment: You record data on how long different brands of gum hold their flavor. The brands under consideration are Scepter, Frost, Dubba Bubba, and 8-3 Gum. For each brand, you test $5$ pieces and get the following average number of minutes that they maintained their flavor, respectively: $33, 24, 12, 15$. All of the gums had a variance of $49$ minutes. Somehow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e3354e007266b7818d4017f076c99c5",
     "grade": false,
     "grade_id": "cell-194468c39e594c98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. (a) Power Overwhelming\n",
    "\n",
    "Determine the power of this experiment at the $0.05$ significance level. Store you answer as `power.gum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "423879de444ec51fa0986c401f8ed439",
     "grade": false,
     "grade_id": "cell-7d57d901a58ca88d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.982298919630504"
      ],
      "text/latex": [
       "0.982298919630504"
      ],
      "text/markdown": [
       "0.982298919630504"
      ],
      "text/plain": [
       "[1] 0.9822989"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groupmeans = c(33, 24, 12, 15)\n",
    "find_power = power.anova.test(groups = length(groupmeans),\n",
    "                            between.var = var(groupmeans), within.var = 49,\n",
    "                            power = NULL, sig.level = 0.05, n=5)\n",
    "power.gum = find_power$power\n",
    "power.gum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0be6d7db2c6f80179ef1e10347f71171",
     "grade": true,
     "grade_id": "cell-6df927426704db4a",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2035766e251858b5bb2c10ab9360eccb",
     "grade": false,
     "grade_id": "cell-62ca24c582e7ea98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. (b) How much gum does it take?\n",
    "\n",
    "Suppose we haven't performed this experiment yet, and are using theoretical gum statistics to get our values. For the same experiment, if we want a final power of $0.85$, how many piece of each gum would we need to chew? Save your answer as `n.gum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47e984f35b6e8ec442263a6b4a402b38",
     "grade": false,
     "grade_id": "cell-cf51e8998a670a26",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "3.39395737421803"
      ],
      "text/latex": [
       "3.39395737421803"
      ],
      "text/markdown": [
       "3.39395737421803"
      ],
      "text/plain": [
       "[1] 3.393957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "find_n = power.anova.test(groups = length(groupmeans),\n",
    "                            between.var = var(groupmeans), within.var = 49,\n",
    "                            power = 0.85, sig.level = 0.05, n= NULL)\n",
    "n.gum = find_n$n\n",
    "\n",
    "n.gum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ecebbd50542183e8ffd3623f21d274d3",
     "grade": true,
     "grade_id": "cell-e5ffdfae92a76e03",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# This cell has hidden test cases that will run after submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
